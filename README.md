# dppo

It works, but not very efficient. I will improve its performance in the future. And my DPPO is different from Deepmind one.

In different environment, it's not easy to determine hyperparameters. For Pong, I don't think it will be better when you clip the gradient, but in other environment, I believe it will have excellent performance.

### test

I'm testing the last change
